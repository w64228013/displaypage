# 视觉标定抓取任务
> version:20181016_1153


## Using LIB

* KinectSDK2.0
* opencv3.4.0
* QT5.10.1

## Process Summary

#### [硬件和安装](#硬件和安装-back)
* 相机：Kinect2.0
* 机械臂：UR3
* 上位机：PC机（win10）

#### [图像抓拍](#图像抓拍-back)
* 使用Kinect2.0,抓拍棋盘格不同角度的图片,保存至本地。

#### [图像标定](#图像标定-back)
* 读取包含棋盘格的图片，设置棋盘格的角点行数、列数、方格实际尺寸、棋盘角点世界坐标。进行标定，得出相机的内参、畸变系数、每张图片的外参（旋转矩阵，平移矩阵）。

#### [图像矫正](#图像矫正-back)
* 使用畸变系数、内参，对图片进行矫正。

#### [图像坐标转世界坐标](#图像坐标转世界坐标-back)
* 使用内参、旋转矩阵、平移矩阵把图像坐标转换为世界坐标。

#### [世界坐标转机械臂坐标](#世界坐标转机械臂坐标-back)
* 根据世界坐标与机械坐标的转换关系，把世界坐标转换为机械臂坐标。

#### [问题](#问题-back)
* 硬件配置。
* 前端界面。
* 后端细节。
* 算法实现。
* 短期任务。

## Process Details

#### 硬件和安装 [BACK↑](#process-summary)
1. 相机测试使用的是Kinect2.0。安装方式是垂直正对目标区域。
   > 20180930:当前测试是没有固定Kinect，使用Kinect在垂直方向对目标区域进行拍照，对照片测试。  
   > 20181016:kinect与区域的垂直与否，决定了图像坐标转换至世界坐标的准确度。
2. 机械臂使用的是UR3。安装方式是目标区域的正前方。
   > 20181016:安装方式为机械臂基座坐标系的z轴与目标区域z轴平行。
3. 上位机使用的是PC机。与相机通讯是通过USB，然后调用KinectSDK2.0。与机械臂通讯是通过以太网，TCPIP协议，根据机械臂脚本指令协议，发送字符串脚本控制。

#### 图像抓拍 [BACK↑](#process-summary)
1. 初始化Kinect。
```
/*
    @Function: kinectcreate
    @Brief: Geting the handle of IColorFrameReader,m_pColorFrameReader is a 
    pointer of IColorFrameReader,and it is initialized as NULL in the 
    constructor.And for many situations, althought we havent connected a 
    Kinect,we still can get the handle of IColorFrameReader.
    @Parameter: 
    @RetVal:

*/
void winkinect::kinectcreate()
{
    /*initializing the kinect START*/
    HRESULT hr;
    hr = GetDefaultKinectSensor(&m_pKinectSensor);
    if (FAILED(hr)){
        return;
    }
    if (m_pKinectSensor){
        // Initialize the Kinect and get the color reader
        IColorFrameSource* pColorFrameSource = NULL;
        hr = m_pKinectSensor->Open();
        if (SUCCEEDED(hr)){
            hr = m_pKinectSensor->get_ColorFrameSource(&pColorFrameSource);
        }
        if (SUCCEEDED(hr)){
            hr = pColorFrameSource->OpenReader(&m_pColorFrameReader);
        }
        SafeRelease(pColorFrameSource);
    }
    if (!m_pKinectSensor || FAILED(hr)){
        return;
    }
    /*initializing the kinect END*/
}
```
2. 读取图像帧,因为读取出的Kinect图像总是水平翻转的，所以拿出来之后要再水平翻转才能与实际相同。
```
/*
    @Function: getcolorframe
    @Brief: Calling this function when you want to get one color frame.
    And by testing ,I found that if you call CopyConvertedFrameDataToArray 
    function with any Format parameters(such as ColorImageFormat_Bgra or ColorImageFormat_Rgba),
    you will always get the frame in flip horizontal compared with real-world.
    RGBQUAD is a struct of a colorframe,we ignore its name and using its 
    struct's sizes.
    @Parameter: 
    @RetVal: unsigned char*,an uchar pointer which to the first address of 
    color frame.

*/
unsigned char* winkinect::getcolorframe()
{
    if (!m_pColorFrameReader){
        return NULL;
    }

    IColorFrame* pColorFrame = NULL;
    unsigned char* retfram = NULL;

    HRESULT hr = m_pColorFrameReader->AcquireLatestFrame(&pColorFrame);

    if (SUCCEEDED(hr)){
        IFrameDescription* pFrameDescription = NULL;
        int nWidth = 0;
        int nHeight = 0;
        ColorImageFormat imageFormat = ColorImageFormat_None;
        UINT nBufferSize = 0;
        RGBQUAD *pBuffer = NULL;

        if (SUCCEEDED(hr)){
            hr = pColorFrame->get_FrameDescription(&pFrameDescription);
        }

        if (SUCCEEDED(hr)){
            hr = pFrameDescription->get_Width(&nWidth);
            m_width = nWidth;
        }

        if (SUCCEEDED(hr)){
            hr = pFrameDescription->get_Height(&nHeight);
            m_height = nHeight;
        }

        if (SUCCEEDED(hr)) {
            hr = pColorFrame->get_RawColorImageFormat(&imageFormat);
        }

        if (SUCCEEDED(hr)){
            if(m_pColorRGBX){
                pBuffer = m_pColorRGBX;
                nBufferSize = nWidth * nHeight * sizeof(RGBQUAD);
                hr = pColorFrame->CopyConvertedFrameDataToArray
                        (nBufferSize, reinterpret_cast<BYTE*>(pBuffer), 
                        ColorImageFormat_Bgra);
            }
            else{
                hr = E_FAIL;
            }
        }
        if (SUCCEEDED(hr)){
            retfram = (unsigned char*)pBuffer;
        }
        SafeRelease(pFrameDescription);
    }
    SafeRelease(pColorFrame);
    return retfram;
}

```

#### 图像标定 [BACK↑](#process-summary)
1. 设置棋盘格的角点行数、列数、方格实际尺寸。
    > 20181016:setboardinfo做了小修改:形参名字，m_boardsize赋值
```
/*
    @Function: setboardinfo
    @Brief: Set the inner corners per a board col and row.
    @Parameter: corPerCol inner corners per a col
                corPerRow inner corners per a row
                bdwidth a length between two corners which have orientation of the horizon or verticality
    @RetVal:

*/
void calibration::setboardinfo(unsigned int corPerCol, unsigned int corPerRow, unsigned int bdwidth)
{
    /*
        cvSize(points_per_row,points_per_colum)
        Size_(_Tp _width, _Tp _height);

    */
    m_boardsize.width = corPerRow;
    m_boardsize.height = corPerCol;

    m_boardwidth.width = bdwidth;
    m_boardwidth.height = bdwidth;
}
```
2. 角点检测，并且设定角点的世界坐标，每个坐标按照角点行数、列数、方格实际尺寸来定义x、y，原点为第一个角点。根据setcornersworldpoint()设定，行表示x，列表示y，每个坐标的偏移由棋盘方格尺寸决定。结果保存至XML文件。
```
/*
    @Function: findcorners
    @Brief: Only finding the corners in one image,and saving the results in 
    the XML files(m_imginfoxml).
    We used m_imginfoxml to storage the results which contained the 
    coordinates of corners.
    m_boardsize and m_boardwidth are declared in cv::Size .
    @Parameter: 
    @RetVal: Reverse

*/
int calibration::findcorners(std::string filename)
{
    std::vector<cv::Point2f> impoints;
    m_imginfoxml = cv::FileStorage(m_xmlfold+m_imginfoxmlname,cv::FileStorage::APPEND);

    cv::Mat view = cv::imread(filename,cv::IMREAD_GRAYSCALE);

    m_imsize.width = view.cols;
    m_imsize.height = view.rows;

    /*find corners*/
    cv::findChessboardCorners( view, m_boardsize, impoints);
    /*make corners' coordinate to subpixel*/
    cv::cornerSubPix( view, impoints, cv::Size(11,11),
                      cv::Size(-1,-1), 
                      cv::TermCriteria(cv::TermCriteria::EPS+cv::TermCriteria::COUNT, 30, 0.1 ));

    m_imgsIMpointslist.push_back(impoints);

    m_imginfoxml<<deletedot(filename).append(GETVARNAME(impoints))<<impoints;

    std::vector<cv::Point3f> wdpoints = setcornersworldpoint();

    m_imginfoxml<<deletedot(filename).append(GETVARNAME(wdpoints))<<wdpoints;
    m_imginfoxml.release();

    m_imgsWDpointslist.push_back(wdpoints);
    m_pointscounts.push_back(m_boardsize.width*m_boardsize.height);

    m_imlist.push_back(filename);
    m_imcounts++;
    return 0;
}

std::vector<cv::Point3f> calibration::setcornersworldpoint()
{
    std::vector<cv::Point3f> wdpoints;

    for (int i=0; i<m_boardsize.height; i++){
        for (int j=0; j<m_boardsize.width; j++){
            cv::Point3f realPoint;
            /* ignoring the z-axis */
            realPoint.x = j * m_boardwidth.width;
            realPoint.y = i * m_boardwidth.height;
            realPoint.z = 0;
            wdpoints.push_back(realPoint);
        }
    }
    return wdpoints;
}

```
3. 画出角点图，保存至本地。
```
/*
    @Function: drawcorners
    @Brief: Calling the cv::drawChessboardCorners and saving the result.
    @Parameter: 
    @RetVal: Reverse

*/
int calibration::drawcorners(std::string filename)
{
    std::vector<cv::Point2f> impoints;
    std::string imIMpointsxmlname = 
    deletedot(filename).append(GETVARNAME(impoints));

    m_imginfoxml = cv::FileStorage(m_xmlfold+m_imginfoxmlname,cv::FileStorage::READ);

    m_imginfoxml[imIMpointsxmlname] >> impoints;
    m_imginfoxml.release();

    cv::Mat view = cv::imread(filename,cv::IMREAD_GRAYSCALE);

    cv::drawChessboardCorners( view, m_boardsize, cv::Mat(impoints), true );

    cv::imwrite(m_drawcornerfold+m_drawcornerprefixname+filename,view);

    return 0;
}
```
4. 标定，内参、外参、畸变系数保存至XML文件。
```
/*
    @Function: calibrateCamera
    @Brief: Calling cv::calibrateCamera.Storaging the results such as 
    intrinsic parameter(m_cameraMat),extrinsic parameter(m_cameraMat),
    distortion coefficients(m_distCoeffs),rotation vector(m_rotationMat),
    transform vector(m_transformMat) in the XML files(m_caminfoxml).
    @Parameter: 
    @RetVal: Reverse

*/
void calibration::calibrateCamera()
{
    void *camMat,*distcoeffs,*rotMat,*tranMat;
    cv::calibrateCamera(m_imgsWDpointslist,m_imgsIMpointslist,
                        m_imsize,m_cameraMat,m_distCoeffs,m_rotationMat,m_transformMat,0);

    m_caminfoxml = cv::FileStorage(m_xmlfold+m_caminfoxmlname,cv::FileStorage::APPEND);
    m_caminfoxml<<GETVARNAME(camMat)<<m_cameraMat<<GETVARNAME(distcoeffs)<<m_distCoeffs;
    m_caminfoxml.release();

    m_imgresxml = cv::FileStorage(m_xmlfold+m_imgresxmlname,cv::FileStorage::APPEND);

    for (size_t i=0; i<m_imcounts; i++){
        m_imgresxml<<deletedot(m_imlist[i]).append(GETVARNAME(rotMat))<<m_rotationMat[i]
                     <<deletedot(m_imlist[i]).append(GETVARNAME(tranMat))<<m_transformMat[i];
    }
    m_imgresxml.release();
}
```
5. 结果评价，把结果保存至txt文件中。
```
void calibration::evaluateError()
{
    double total_err = 0.0; 
    double err = 0.0; 
    std::vector<cv::Point2f> tempWDpoints; 
    /*evaluate the result of calibration */
    /*fout 是txt 输出文件 fout = std::ofstream("caliberation_result.txt"); */
    fout<<"每幅图像的标定误差：\n";  

    for (size_t i=0;i<m_imcounts;i++)
    {
        std::vector<cv::Point3f> tempPointSet = m_imgsWDpointslist[i];
        /* 通过得到的摄像机内外参数，对空间的三维点进行重新投影计算，
        得到新的投影点 从世界坐标得出图像坐标*/
        cv::projectPoints(tempPointSet,m_rotationMat[i],
            m_transformMat[i],m_cameraMat,m_distCoeffs,tempWDpoints);
        /* 计算新的投影点和旧的投影点之间的误差 */
        std::vector<cv::Point2f> tempImagePoint = m_imgsIMpointslist[i];

        cv::Mat tempImagePointMat = cv::Mat(1,tempImagePoint.size(),CV_32FC2);
        cv::Mat tempWDpointsMat = cv::Mat(1,tempWDpoints.size(), CV_32FC2);
        for (size_t j = 0 ; j < tempImagePoint.size(); j++)
        {
            tempWDpointsMat.at<cv::Vec2f>(0,j) = 
            cv::Vec2f(tempWDpoints[j].x, tempWDpoints[j].y);

            tempImagePointMat.at<cv::Vec2f>(0,j) = 
            cv::Vec2f(tempImagePoint[j].x, tempImagePoint[j].y);
        }

        err = cv::norm(tempWDpointsMat, tempImagePointMat, cv::NORM_L2);
        total_err += err/=  m_pointscounts[i];
        fout<<"第"<<i+1<<"幅图像的平均误差："<<err<<"像素"<<endl;
    }
    fout<<"总体平均误差："<<total_err/m_imcounts<<"像素"<<endl<<endl;
}
```

#### 图像矫正 [BACK↑](#process-summary)
根据内参和畸变系数，对图片进行矫正。

```
/*
    @Function: rectifyimage
    @Brief: Calling cv::initUndistortRectifyMap and cv::remap.Rectifying the 
    image by intrinsic parameter and distortion coefficients.
    @Parameter: 
    @RetVal: Reverse

*/
void calibration::rectifyimage()
{
    /*显示标定结果*/
    cv::Mat mapx = cv::Mat(m_imsize,CV_32FC1);
    cv::Mat mapy = cv::Mat(m_imsize,CV_32FC1);
    cv::Mat R = cv::Mat::eye(3,3,CV_32F);

    m_caminfoxml = cv::FileStorage(m_xmlfold+m_caminfoxmlname,cv::FileStorage::READ);

    cv::Mat camMat = cv::Mat(3, 3, CV_32FC1, cv::Scalar::all(0));
    cv::Mat distcoeffs = cv::Mat(1, 5, CV_32FC1,cv::Scalar::all(0));
    m_caminfoxml[GETVARNAME(camMat)]>>camMat;
    m_caminfoxml[GETVARNAME(distcoeffs)]>>distcoeffs;

    /*矫正后图像保存路径和前缀*/
    std::string prefix = "./over/afterconvert_";
    for (auto filename:m_imlist){
        /*得到映射mapx mapy*/
        cv::initUndistortRectifyMap(camMat,distcoeffs,R,
            camMat,m_imsize,CV_32FC1,mapx,mapy);
        cv::Mat imageSource = cv::imread(filename);
        cv::Mat newimage = imageSource.clone();
        /*得出矫正图片*/
        cv::remap(imageSource,newimage,mapx, mapy, cv::INTER_LINEAR);
        cv::imwrite(prefix+filename,newimage);
    }
    m_caminfoxml.release();
}
```
#### 图像坐标转世界坐标 [BACK↑](#process-summary)
根据输入的图像坐标，转换成相应的世界坐标。其中相机以垂直拍摄的方式，配合标定板，确认世界二维坐标。
```
/*
    @Function: impoint2worldpoint
    @Brief: Transforming image-coordinate to world-coordinate 
    and storaging in the XML files(m_img2wdxml).
    @Parameter: x:image-coordinate of x-axis
    @Parameter: y:image-coordinate of y-axis
    @RetVal: Reverse

*/
void calibration::impoint2worldpoint(double x, double y, std::string filename)
{
    /*去除filename的路径，只保留文件名*/
    QFileInfo fileinfo(QString(filename.data()));
    filename = fileinfo.fileName().toStdString();

    /* 保存每幅图像的旋转矩阵 */
    cv::Mat rotation_matrix = cv::Mat(3,3,CV_32FC1, cv::Scalar::all(0));
    /*待转换图像坐标*/
    cv::Mat imPosPoint = cv::Mat::ones(3,1,cv::DataType<double>::type);

    m_caminfoxml = 
    cv::FileStorage(m_xmlfold+m_caminfoxmlname,cv::FileStorage::READ);
    m_imgresxml = 
    cv::FileStorage(m_xmlfold+m_imgresxmlname,cv::FileStorage::READ);

    cv::Mat camMat = cv::Mat(3, 3, CV_32FC1, cv::Scalar::all(0));
    cv::Mat distcoeffs = cv::Mat(1, 5, CV_32FC1,cv::Scalar::all(0));
    m_caminfoxml[GETVARNAME(camMat)]>>camMat;
    m_caminfoxml[GETVARNAME(distcoeffs)]>>distcoeffs;
    m_caminfoxml.release();

    cv::Mat rotMat;
    cv::Mat tranMat;
    /*Getting the matrix from XML files*/
    m_imgresxml[deletedot(filename).append(GETVARNAME(rotMat))]>>rotMat;
    m_imgresxml[deletedot(filename).append(GETVARNAME(tranMat))]>>tranMat;
    m_imgresxml.release();

    /*需要被转换的图像坐标*/
    imPosPoint.at<double>(0,0) = x;
    imPosPoint.at<double>(1,0) = y;

    /*rotation_matrix 旋转向量转换为矩阵*/
    cv::Rodrigues(rotMat,rotation_matrix);

    cv::Point2f inputPoint(x,y);
    std::vector<cv::Point2f> inputDistortedPoints;
    std::vector<cv::Point2f> outputUndistortedPoints;
    inputDistortedPoints.push_back(inputPoint);

    cv::undistortPoints(inputDistortedPoints, outputUndistortedPoints,camMat, distcoeffs, cv::noArray(), camMat);

    /*重新调整坐标值*/                 
    imPosPoint.at<double>(0,0) = outputUndistortedPoints.at(0).x;
    imPosPoint.at<double>(1,0) = outputUndistortedPoints.at(0).y;

    /*
     * 具体可以看如下的网站，根据公式，测下来在得出的平面坐标误差不大
     * 
     https://stackoverflow.com/questions/12299870/computing-x-y-coordinate-3d-from-image-point
    */
    /*tempMat 是网站上公式的等式左边部分 tempMat2 是等式右边部分*/
    cv::Mat tempMat, tempMat2;
    double s, zConst = 0;

    tempMat = rotation_matrix.inv() * camMat.inv() * imPosPoint;
    tempMat2 = rotation_matrix.inv() * tranMat;

    s = zConst + tempMat2.at<double>(2,0);
    s /= tempMat.at<double>(2,0);

    /*求出s后，这也是按照公式*/
    cv::Mat wcPoint = rotation_matrix.inv() * (s * camMat.inv() * imPosPoint - tranMat);
    /*realPoint 是最终世界坐标*/
    cv::Point3f realPoint(wcPoint.at<double>(0, 0), wcPoint.at<double>(1, 0), wcPoint.at<double>(2, 0));

    m_img2wdxml = cv::FileStorage(m_xmlfold+m_img2wdxmlname,cv::FileStorage::APPEND);
    m_img2wdxml<<deletedot(filename).append("_"+std::to_string(m_im2wdcounts))
    <<realPoint;
    m_img2wdxml.release();
    m_im2wdcounts++;
}
```

#### 世界坐标转机械臂坐标 [BACK↑](#process-summary)
> 20180930:这里的坐标系先仅仅是讨论平面坐标系，z轴默认为0，且坐标不考虑欧拉角。  
> 20181021:旋转按照固定坐标旋转;添加了python代码。

1. 确认三个点
    * 测量三个点在机械臂坐标系中的坐标值。
    > 均可通过机械臂控制面板得出。
    * 第一个点为世界坐标系的原点。
    * 第二个点为世界坐标系的x轴正方向坐标轴上的点。
    * 第三个点为世界坐标系的y轴正方向区域的点。
    > z轴可以通过右手法则得出方向，所有坐标的z轴默认为0。
2. 建立联系 
    * 通过三个点，我们可以建立起世界坐标系相对于机械臂坐标系转换方式。
    * 第一个点代表了x和y轴的平移量。
    * 第二、第三个点代表了x和y轴的方向。
    > 得到这三个点，相当于得到了整个世界坐标系相对于机械臂坐标系的平移量、旋转量（二维）。 
3. 转换方式  
    1. 旋转。
    2. 平移。
    3. 根据y方向做x方向对称。
> 20180930:这里还需要测试验证，此前只对平移做了验证。   
> 20181021:已经验证完毕，转换顺序做了改变。

matlab code:
> 20181011:象限部分判断有误。  
> 20181021:y方向翻转部分做了较大改动。

```
%%
% 这里默认在一张图像中，世界x轴方向为图像从左往右的方向，世界y轴方向为从右往左的方向。
% 因为这个世界坐标系是根据棋盘格标定时定义的坐标系，并且棋盘格在图片中是与图像边缘上下对齐。
% a是第一个点，表示世界坐标原点在机械臂坐标的值。
% b是第二个点，表示世界坐标x轴在机械臂坐标系中的方向，b点在定义的x轴上。
% c是第三个点，表示世界坐标y轴在机械臂坐标系中的方向，c点在定义的y轴方向的区域。
% They are column vectors.
a = [ax,ay]';
b = [bx,by]';
c = [cx,cy]';
% T 是平移向量。
T = a;
% e是待转换的世界坐标系中的坐标。
e = [ex,ey]';

%%
% step1:
% theta，机械坐标系中设定的世界坐标x轴与a点的水平方向的夹角。
% d，b在a点水平方向上的投影点。
d = [b(1),a(2)]';
ab = b-a;
ad = d-a;
theta = acos(dot(ab,ad)/(norm(ab)*norm(ad)));

% 旋转
% clockwise 顺时针旋转矩阵，counterclockwise 逆时针 
u = theta;
clockwise = [cos(u),sin(u);-sin(u),cos(u)];
counterclockwise = clockwise';

% b(1) > a(1) && b(2) > a(2) 
% 说明b点在第四象限，也就是说明x轴的方向是朝向第四象限。根据角度逆时针旋转。
if (b(1) > a(1) && b(2) > a(2))
    e = counterclockwise*e;

% b(1) > a(1) && b(2) < a(2)
% 说明b点在第一象限，也就是说明x轴的方向是朝向第一象限。根据角度顺时针旋转。   
elseif (b(1) > a(1) && b(2) < a(2))
    e = clockwise*e;

% b(1) < a(1) && b(2) < a(2)
% 说明b点在第二象限，也就是说明x轴的方向是朝向第二象限。
% 根据角度顺时针旋转，并且角度要加减去PI。   
elseif (b(1) < a(1) && b(2) < a(2)) 
    u = PI - u ;
    clockwise = [cos(u),sin(u);-sin(u),cos(u)];
    counterclockwise = clockwise';
    e = clockwise*e;

% b(1) < a(1) && b(2) > a(2)
% 说明b点在第三象限，也就是说明x轴的方向是朝向第三象限。
% 根据角度逆时针旋转，并且角度要加减去PI。   
elseif (b(1) < a(1) && b(2) > a(2)) 
    u = PI - u ;
    clockwise = [cos(u),sin(u);-sin(u),cos(u)];
    counterclockwise = clockwise';
    e = counterclockwise*e;
end

%% step2:
% 平移
e = e + T;

%% step3:
% 翻转
% d2cross为叉乘，d2cross < 0 
% 说明c点在ab向量的逆时针方向，我们现在y轴的方向是顺时针方向，所以需要做关于y轴坐标的对称点。
% 因为图像坐标系的y轴是相反的所以<0 是逆时针方向
ab = b-a;
ac = c-a;
d2cross = ab(1)*ac(2)-ab(2)*ac(1);
% 
if d2cross < 0 
    %A,B,C是直线的系数
    C = -ab(2)*a(1)+ab(1)*a(2);
    A = ab(2);
    B = -ab(1);

    % 做point关于ab向量所在直线的对称点
    point = e;

    xnew = (B^2-A^2)*point(1)-2*A*B*point(2)-2*A*C;
    xnew = xnew/(A^2+B^2);
    ynew = (A^2-B^2)*point(2)-2*A*B*point(1)-2*B*C;
    ynew = ynew/(A^2+B^2);

    e = [xnew,ynew]';
end 

```
python code:
```
import numpy as np
import numpy.linalg as nplg
import math

# test
ax = -190.30
ay = 318.78
bx = -296.13
by = 215.84
cx = -296.16
cy = 326.23

ex = 200
ey = 200

a = np.mat([ax, ay]).transpose()
b = np.mat([bx, by]).transpose()
c = np.mat([cx, cy]).transpose()
# T 是平移向量。
T = a
# e是待转换的世界坐标系中的坐标。
e = np.mat([ex, ey]).transpose()

# # step1:
# theta，机械坐标系中设定的世界坐标x轴与a点的水平方向的夹角。
# d，b在a点水平方向上的投影点。
d = np.mat([b[0, 0], a[1, 0]]).transpose()
ab = b - a
ad = d - a
dotres = np.multiply(ab, ad).sum()
theta = math.acos(dotres / (nplg.norm(ab, 2) * nplg.norm(ad, 2)))

# 旋转
# clockwise 顺时针旋转矩阵，counterclockwise 逆时针
# 20181012:
u = theta
clockwise = np.mat([[math.cos(u), math.sin(u)], [-math.sin(u), math.cos(u)]])
counterclockwise = clockwise.transpose()

if (b[0, 0] > a[0, 0]) and (b[1, 0] > a[1, 0]):
    e = counterclockwise * e
    print("b点在第四象限，逆时针旋转角度 =",math.degrees(u))

elif (b[0, 0] > a[0, 0]) and (b[1, 0] < a[1, 0]):
    e = clockwise * e
    print("b点在第一象限，顺时针旋转角度 =",math.degrees(u))

elif (b[0, 0] < a[0, 0]) and (b[1, 0] < a[1, 0]):
    u = math.pi - u
    clockwise = np.mat([[math.cos(u), math.sin(u)], [-math.sin(u), math.cos(u)]])
    counterclockwise = clockwise.transpose()
    e = clockwise * e
    print("b点在第二象限，顺时针旋转角度 =",math.degrees(u))

elif (b[0, 0] < a[0, 0]) and (b[1, 0] > a[1, 0]):
    u = math.pi - u
    clockwise = np.mat([[math.cos(u), math.sin(u)], [-math.sin(u), math.cos(u)]])
    counterclockwise = clockwise.transpose()
    e = counterclockwise * e
    print("b点在第三象限，逆时针旋转角度 =",math.degrees(u))

# # step2:
# 平移
e = e + T

# # step3:

ab = b - a
ac = c - a
d2cross = ab[0, 0] * ac[1, 0] - ab[1, 0] * ac[0, 0]

if d2cross < 0:
    C = -ab[1, 0] * a[0, 0] + ab[0, 0] * a[1, 0]
    A = ab[1, 0]
    B = -ab[0, 0]
    # 求 point 关于 ab向量所在直线的对称点
    point = e

    xnew = (np.square(B) - np.square(A)) * point[0, 0] - 2 * A * B * point[1, 0] - 2 * A * C
    xnew = xnew / (np.square(A) + np.square(B))
    ynew = (np.square(A) - np.square(B)) * point[1, 0] - 2 * A * B * point[0, 0] - 2 * B * C
    ynew = ynew / (np.square(A) + np.square(B))

    e[0, 0] = xnew
    e[1, 0] = ynew
    print("c点在ab逆时针方向，做对称")

else:
    print("c点在ab顺时针方向，不做对称")

print("转换后机械臂坐标:\n",e)
```

#### 问题 [BACK↑](#process-summary)
1. 硬件配置：需要精确了解相机和机械臂的关键技术参数。
    > 20181021:kinect可能垂直支撑有点问题，尝试使用工业相机代替，需要查样本了解工业相机通讯。
2. 前端界面：具体要求确定；界面整体编写，当前进度为初步界面。
    > 20181021:第一版界面初步编写完成。
3. 后端细节：具体要求确定；数据的保存格式；语言的选择。
    > 20181021:纯标定部分暂时用C++实现。
4. 算法实现：标定部分需要再细化测试；~~世界坐标到机械臂坐标转换关系需要测试验证~~，比如测试标定板在图像中不同角度对转换关系的影响；后期再根据需求，加上机械臂反馈信息和运动规划。
    > 20181021:世界坐标系到机械臂坐标系转换关系已经验证。
5. 短期任务：
    * 使用工业相机(GS3-PGE-91QS6M-C)代替kinect。原因：场景不需要深度信息；Kinect体积过大，不方便安装；实验室正好有空余的工业相机。
    * 蔡晨把现有的物体识别部分接进或者对接标定程序。原因：做成完整的流程系统进行测试。


